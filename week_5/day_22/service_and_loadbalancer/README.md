# Service and load balancer
## instructions
ğŸ‘‰ CrÃ©ez un manifeste "mywebserver-deployment.yml" dÃ©diÃ© Ã  un dÃ©ploiement de pods en suivant les contraintes suivantes :
- Le nom de lâ€™application dÃ©ployÃ©e sera "mywebserver"
- Le nom du manifeste de dÃ©ploiement sera "mws-deployment"
- Le conteneur dÃ©ployÃ© sera nommÃ© "nginx-hello", basÃ© sur lâ€™image nginxdemos/hello dans sa derniÃ¨re version et devra exposer le port 80
- 5 pods devront Ãªtre utilisÃ©s pour le dÃ©ploiement du conteneur "nginx-hello"

ğŸ‘‰ Appliquez le manifeste crÃ©Ã© prÃ©cÃ©demment afin de dÃ©ployer les pods contenant chacun un seul conteneur "nginx-hello".

```sh
kubectl apply -f mywebserver-deployment.yml
```

LA NOTION DE SERVICE
Comme vu dans les challenges prÃ©cÃ©dents, la commande kubectl port-forward permet de binder un port dâ€™un conteneur sur la machine hÃ´te, ce qui est utile pour comprendre le fonctionnement de Kubernetes et s'entraÃ®ner, mais pas vraiment adaptÃ© dans un environnement de production.
En effet, la notion de service avec Kubernetes sera plus adaptÃ©e car elle permettra de rendre disponible une application web sur internet, mais Ã©galement de rediriger le trafic Ã©quitablement entre les pods afin de rÃ©partir la charge, câ€™est ce que lâ€™on appelle un load balancer.

ğŸ‘‰ CrÃ©ez un nouveau fichier nommÃ© "mywebserver-service.yml" et complÃ©tez le service ci-dessous afin de lâ€™adapter Ã  votre dÃ©ploiement prÃ©cÃ©demment crÃ©Ã©.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mws-service
  labels:
    app: ???
spec:
  type: LoadBalancer
  ports:
  - name: http
    port: ???
    protocol: TCP
    targetPort: ???
  selector:
    app: ???
  sessionAffinity: None
```

ğŸ‘‰ Appliquez le service crÃ©Ã© prÃ©cÃ©demment via la commande kubectl apply.

ğŸ‘‰ Trouvez lâ€™option Ã  appliquer Ã  la commande kubectl get afin de vÃ©rifier lâ€™Ã©tat des services.

Lâ€™output de cette commande doit afficher une nouvelle ligne contenant "mws-service". Dans un environnement de production, la colonne "EXTERNAL-IP" affiche lâ€™IP publique permettant de joindre le service et donc lâ€™application dÃ©ployÃ©e via Kubernetes.

Fort heureusement, notre meilleur ami minikube permet de rediriger lâ€™hÃ´te local vers le service afin de simuler un contexte dans lequel lâ€™environnement de production (dÃ©ployÃ© via AWS, par exemple) expose une IP publique. Ã‡a peut paraÃ®tre compliquÃ©, mais rassurez-vous, Kubernetes se charge de tout !

ğŸ‘‰ Utilisez la commande suivante afin dâ€™obtenir une URL censÃ©e rediriger, via le service dÃ©ployÃ© prÃ©cÃ©demment, vers un pod exposant le port 80 du conteneur quâ€™il hÃ©berge.

```sh
minikube service mws-service --url
```
ğŸ‘‰ Ouvrez lâ€™URL affichÃ©e par la commande prÃ©cÃ©dente Ã  partir dâ€™un navigateur afin de constater que lâ€™image "nginxdemos/hello" affiche les informations du serveur web ou plus prÃ©cisÃ©ment celles du pod hÃ©bergeant lâ€™application.

ğŸ‘‰ RÃ©cupÃ©rez le nom du pod affichÃ© sur la ligne "Server name" afin de le supprimer via la commande kubectl delete.

ğŸ‘‰ Actualisez la page prÃ©cÃ©demment ouverte afin de constater quâ€™un autre pod a pris le relais automatiquement grÃ¢ce au manifeste de dÃ©ploiement et au load balancer configurÃ© via le service.

ğŸ‘‰ Pour finir, supprimez le manifeste de dÃ©ploiement ainsi que le service de ce challenge.

```sh
kubectl delete deployment mws-deployment
kubectl delete service mws-service
```

## commands

```sh
kubectl apply -f mywebserver-deployment.yml
kubectl apply -f mywebserver-service.yml
kubectl get all
minikube service msw-service --url
kubectl delete pod mws-deployment-6ff5c44df4-bzt77
kubectl delete deployment mws-deployment
kubectl delete service mws-service 
```
